{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# CSC 786 - EDR Evasion Analysis: io_uring vs Traditional Syscalls\n",
    "\n",
    "**Author:** Michael Mendoza | **Course:** CSC 786 | **Institution:** Dakota State University\n",
    "\n",
    "---\n",
    "\n",
    "## Metrics Evaluated\n",
    "\n",
    "### Primary Metrics\n",
    "1. **Detection Rate** - Proportion of runs producing at least one audit hit\n",
    "2. **False Negative Rate** - Runs where behavior occurred but no alert generated\n",
    "3. **Time-to-Detection** - Time between execution and first alert\n",
    "\n",
    "### Secondary Metrics\n",
    "4. **io_uring Setup Detection** - Whether io_uring initialization is visible\n",
    "5. **Evasion Delta** - Detection rate difference (traditional - io_uring)\n",
    "6. **Path-Specific Detection** - Whether the specific test file appears in audit logs\n",
    "\n",
    "## MITRE ATT&CK Mapping\n",
    "- T1059 - Command and Scripting Interpreter (exec_cmd)\n",
    "- T1071 - Application Layer Protocol (net_connect)\n",
    "- T1005 - Data from Local System (file_io)\n",
    "- T1562.001 - Impair Defenses (io_uring evasion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "plt.rcParams.update({'figure.figsize': (10, 6), 'font.size': 11})\n",
    "\n",
    "RESULTS_DIR = Path('results')\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "TABLES_DIR = RESULTS_DIR / 'tables'\n",
    "for d in [FIGURES_DIR, TABLES_DIR]: d.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Output: {RESULTS_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [Path('../data/processed'), Path('data/processed'), Path('../../data/processed')]:\n",
    "    if p.exists():\n",
    "        processed_dir = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError('No data/processed directory found')\n",
    "\n",
    "csvs = sorted(processed_dir.glob('runs_*.csv'))\n",
    "if not csvs: raise FileNotFoundError('No runs_*.csv found')\n",
    "\n",
    "csv_path = csvs[-1]\n",
    "print(f'Loading: {csv_path}')\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f'Shape: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "## 2) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing columns for backward compatibility\n",
    "if 'iouring_hits' not in df.columns: df['iouring_hits'] = 0\n",
    "if 'time_to_detect' not in df.columns: df['time_to_detect'] = -1\n",
    "if 'path_hits' not in df.columns: df['path_hits'] = -1\n",
    "\n",
    "# Classify cases\n",
    "df['method'] = df['case'].apply(lambda x: 'io_uring' if 'uring' in x.lower() else 'traditional')\n",
    "df['operation'] = df['case'].apply(lambda x:\n",
    "    'File Write' if 'file_io' in x.lower() else\n",
    "    'File Read' if 'read_file' in x.lower() or 'openat' in x.lower() else\n",
    "    'Network' if 'net' in x.lower() else\n",
    "    'Process Exec' if 'exec' in x.lower() else 'Other')\n",
    "\n",
    "# Derived metrics\n",
    "df['total_audit_hits'] = df['file_hits'] + df['net_hits'] + df['exec_hits']\n",
    "df['audit_detected'] = df['total_audit_hits'] > 0\n",
    "df['wazuh_detected'] = df['wazuh_alerts'] > 0\n",
    "df['iouring_detected'] = df['iouring_hits'] > 0\n",
    "df['ttd_seconds'] = df['time_to_detect'].replace(-1, np.nan)\n",
    "df['path_detected'] = df['path_hits'].apply(lambda x: True if x > 0 else (False if x == 0 else None))\n",
    "\n",
    "print('Cases:', df['case'].unique().tolist())\n",
    "print(f'Iterations: {df.iteration.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detection-header",
   "metadata": {},
   "source": [
    "## 3) Detection Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detection-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_rates = df.groupby('case').agg({\n",
    "    'audit_detected': 'mean',\n",
    "    'iouring_detected': 'mean',\n",
    "    'wazuh_detected': 'mean',\n",
    "    'iteration': 'count'\n",
    "}).rename(columns={'iteration': 'N', 'audit_detected': 'Audit Rate',\n",
    "                   'iouring_detected': 'iouring Setup Rate', 'wazuh_detected': 'Wazuh Rate'})\n",
    "det_rates['Method'] = det_rates.index.map(lambda x: 'io_uring' if 'uring' in x else 'traditional')\n",
    "\n",
    "print('=== Detection Rates by Case ===')\n",
    "display_rates = det_rates.copy()\n",
    "for c in ['Audit Rate', 'iouring Setup Rate', 'Wazuh Rate']:\n",
    "    display_rates[c] = (display_rates[c] * 100).round(1).astype(str) + '%'\n",
    "print(display_rates.to_string())\n",
    "det_rates.to_csv(TABLES_DIR / 'detection_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "method-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_summary = df.groupby('method')['audit_detected'].agg(['mean', 'sum', 'count'])\n",
    "method_summary.columns = ['Detection Rate', 'Detections', 'Total Runs']\n",
    "print('\\n=== Traditional vs io_uring ===')\n",
    "print(method_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path-header",
   "metadata": {},
   "source": [
    "## 4) Path-Specific Detection (KEY EVASION METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "path-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('PATH-SPECIFIC DETECTION ANALYSIS')\n",
    "print('='*70)\n",
    "\n",
    "file_ops = df[df['path_hits'] >= 0].copy()\n",
    "if len(file_ops) > 0:\n",
    "    path_summary = file_ops.groupby('case').agg({\n",
    "        'path_hits': ['sum', 'mean'],\n",
    "        'iteration': 'count'\n",
    "    })\n",
    "    path_summary.columns = ['Total Path Hits', 'Mean Path Hits', 'Total Runs']\n",
    "    path_summary['Path Detection Rate'] = file_ops.groupby('case').apply(\n",
    "        lambda x: (x['path_hits'] > 0).mean() * 100\n",
    "    )\n",
    "    print(path_summary.round(2).to_string())\n",
    "    path_summary.to_csv(TABLES_DIR / 'path_detection.csv')\n",
    "    print('\\n>>> Traditional: HIGH path detection = syscalls visible')\n",
    "    print('>>> io_uring: LOW/ZERO path detection = EVASION CONFIRMED')\n",
    "else:\n",
    "    print('No path-specific data available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fn-header",
   "metadata": {},
   "source": [
    "## 5) False Negative Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-negatives",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== False Negative Rates ===')\n",
    "file_ops = df[df['path_hits'] >= 0]\n",
    "if len(file_ops) > 0:\n",
    "    fn_rates = file_ops.groupby('case').apply(lambda x: (x['path_hits'] == 0).mean())\n",
    "else:\n",
    "    fn_rates = df.groupby('case')['audit_detected'].apply(lambda x: 1 - x.mean())\n",
    "fn_df = fn_rates.to_frame('False Negative Rate')\n",
    "fn_df['Method'] = fn_df.index.map(lambda x: 'io_uring' if 'uring' in x else 'traditional')\n",
    "fn_display = fn_df.copy()\n",
    "fn_display['False Negative Rate'] = (fn_display['False Negative Rate'] * 100).round(1).astype(str) + '%'\n",
    "print(fn_display.to_string())\n",
    "fn_df.to_csv(TABLES_DIR / 'false_negative_rates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ttd-header",
   "metadata": {},
   "source": [
    "## 6) Time-to-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ttd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttd = df[df['ttd_seconds'].notna()].groupby('case')['ttd_seconds'].agg(['count', 'median', 'mean', 'std'])\n",
    "ttd.columns = ['Detected', 'Median TTD', 'Mean TTD', 'Std']\n",
    "if len(ttd) > 0:\n",
    "    print('=== Time-to-Detection (seconds) ===')\n",
    "    print(ttd.round(3).to_string())\n",
    "    ttd.to_csv(TABLES_DIR / 'time_to_detection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bypass-header",
   "metadata": {},
   "source": [
    "## 7) Syscall Bypass Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bypass-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ('file_io_traditional', 'file_io_uring', 'File Write'),\n",
    "    ('read_file_traditional', 'openat_uring', 'File Read'),\n",
    "    ('net_connect_traditional', 'net_connect_uring', 'Network'),\n",
    "]\n",
    "\n",
    "print('='*70)\n",
    "print('SYSCALL BYPASS VALIDATION')\n",
    "print('='*70)\n",
    "\n",
    "validation = []\n",
    "for trad_case, uring_case, op in pairs:\n",
    "    trad = df[df['case'] == trad_case]\n",
    "    uring = df[df['case'] == uring_case]\n",
    "    if len(trad) == 0 or len(uring) == 0: continue\n",
    "    \n",
    "    if 'path_hits' in df.columns and trad['path_hits'].iloc[0] >= 0:\n",
    "        t_metric = (trad['path_hits'] > 0).mean() * 100\n",
    "        u_metric = (uring['path_hits'] > 0).mean() * 100\n",
    "    else:\n",
    "        t_metric = trad['audit_detected'].mean() * 100\n",
    "        u_metric = uring['audit_detected'].mean() * 100\n",
    "    \n",
    "    u_setup = (uring['iouring_hits'] > 0).mean() * 100\n",
    "    bypass = t_metric > 50 and u_metric < 50 and u_setup > 50\n",
    "    \n",
    "    validation.append({'Operation': op, 'Trad Detection %': t_metric, \n",
    "                       'Uring Detection %': u_metric, 'Uring Setup %': u_setup,\n",
    "                       'Bypass Confirmed': 'YES' if bypass else 'NO'})\n",
    "    print(f'\\n{op}: Trad={t_metric:.0f}%, Uring={u_metric:.0f}%, Setup={u_setup:.0f}%')\n",
    "    print(f'  >>> Bypass: {\"YES\" if bypass else \"NO\"}')\n",
    "\n",
    "pd.DataFrame(validation).to_csv(TABLES_DIR / 'syscall_bypass_validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## 8) Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Detection Rates\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rates = df.groupby('case')['audit_detected'].mean() * 100\n",
    "colors = ['#2ecc71' if 'traditional' in c else '#e74c3c' for c in rates.index]\n",
    "bars = ax.bar(range(len(rates)), rates.values, color=colors, edgecolor='black')\n",
    "ax.set_xticks(range(len(rates)))\n",
    "ax.set_xticklabels(rates.index, rotation=45, ha='right')\n",
    "ax.set_ylabel('Detection Rate (%)')\n",
    "ax.set_title('Figure 1: Audit Detection Rate by Test Case', fontweight='bold')\n",
    "ax.set_ylim(0, 110)\n",
    "for bar, val in zip(bars, rates.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, f'{val:.0f}%', ha='center', fontweight='bold')\n",
    "from matplotlib.patches import Patch\n",
    "ax.legend(handles=[Patch(color='#2ecc71', label='Traditional'), Patch(color='#e74c3c', label='io_uring')], loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig1_detection_rates.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Path Detection (Key Metric)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "file_cases = df[df['path_hits'] >= 0]['case'].unique()\n",
    "if len(file_cases) > 0:\n",
    "    path_rates = df[df['path_hits'] >= 0].groupby('case').apply(lambda x: (x['path_hits'] > 0).mean() * 100)\n",
    "    colors = ['#2ecc71' if 'traditional' in c else '#e74c3c' for c in path_rates.index]\n",
    "    bars = ax.bar(range(len(path_rates)), path_rates.values, color=colors, edgecolor='black')\n",
    "    ax.set_xticks(range(len(path_rates)))\n",
    "    ax.set_xticklabels(path_rates.index, rotation=45, ha='right')\n",
    "    ax.set_ylabel('Path Detection Rate (%)')\n",
    "    ax.set_title('Figure 2: Path-Specific Detection (KEY EVASION METRIC)', fontweight='bold')\n",
    "    ax.set_ylim(0, 110)\n",
    "    for bar, val in zip(bars, path_rates.values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, f'{val:.0f}%', ha='center', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig2_path_detection.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Paired Comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "labels = ['File Write', 'File Read', 'Network']\n",
    "trad_cases = ['file_io_traditional', 'read_file_traditional', 'net_connect_traditional']\n",
    "uring_cases = ['file_io_uring', 'openat_uring', 'net_connect_uring']\n",
    "t_means = [df[df['case']==c]['total_audit_hits'].mean() for c in trad_cases]\n",
    "u_means = [df[df['case']==c]['total_audit_hits'].mean() for c in uring_cases]\n",
    "x = np.arange(len(labels))\n",
    "ax.bar(x - 0.175, t_means, 0.35, label='Traditional', color='#2ecc71', edgecolor='black')\n",
    "ax.bar(x + 0.175, u_means, 0.35, label='io_uring', color='#e74c3c', edgecolor='black')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('Mean Audit Events')\n",
    "ax.set_title('Figure 3: Mean Audit Events - Traditional vs io_uring', fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig3_paired_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "hm_data = df.groupby('case')[['file_hits', 'net_hits', 'exec_hits', 'iouring_hits']].apply(lambda x: (x > 0).mean() * 100)\n",
    "hm_data.columns = ['File', 'Network', 'Exec', 'io_uring Setup']\n",
    "hm_data = hm_data.reindex(sorted(hm_data.index, key=lambda x: (0 if 'traditional' in x else 1, x)))\n",
    "sns.heatmap(hm_data, annot=True, fmt='.0f', cmap='RdYlGn', vmin=0, vmax=100, cbar_kws={'label': 'Detection %'}, ax=ax)\n",
    "ax.set_title('Figure 4: Detection Heatmap', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig4_heatmap.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fig5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Evasion Effectiveness\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ops = ['File Write', 'File Read', 'Network']\n",
    "evasion = []\n",
    "for t, u in [('file_io_traditional', 'file_io_uring'), ('read_file_traditional', 'openat_uring'), ('net_connect_traditional', 'net_connect_uring')]:\n",
    "    trad_df = df[df['case']==t]\n",
    "    uring_df = df[df['case']==u]\n",
    "    if 'path_hits' in df.columns and trad_df['path_hits'].iloc[0] >= 0:\n",
    "        tr = (trad_df['path_hits'] > 0).mean() * 100\n",
    "        ur = (uring_df['path_hits'] > 0).mean() * 100\n",
    "    else:\n",
    "        tr = trad_df['audit_detected'].mean() * 100\n",
    "        ur = uring_df['audit_detected'].mean() * 100\n",
    "    evasion.append(tr - ur)\n",
    "colors = ['#3498db' if e > 50 else '#f39c12' if e > 0 else '#95a5a6' for e in evasion]\n",
    "ax.barh(ops, evasion, color=colors, edgecolor='black')\n",
    "for i, v in enumerate(evasion): ax.text(max(v + 2, 5), i, f'{v:.0f}%', va='center', fontweight='bold')\n",
    "ax.set_xlabel('Detection Rate Reduction (%)')\n",
    "ax.set_title('Figure 5: io_uring Evasion Effectiveness', fontweight='bold')\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'fig5_evasion.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mitre-header",
   "metadata": {},
   "source": [
    "## 9) MITRE ATT&CK Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mitre",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitre = pd.DataFrame([\n",
    "    {'Technique': 'T1059', 'Name': 'Command and Scripting Interpreter', 'Test Case': 'exec_cmd_traditional', 'io_uring Evasion': 'N/A (execve not supported)'},\n",
    "    {'Technique': 'T1005', 'Name': 'Data from Local System', 'Test Case': 'file_io_*, read_file_*, openat_*', 'io_uring Evasion': 'Yes'},\n",
    "    {'Technique': 'T1071', 'Name': 'Application Layer Protocol', 'Test Case': 'net_connect_*', 'io_uring Evasion': 'Yes'},\n",
    "    {'Technique': 'T1562.001', 'Name': 'Impair Defenses: Disable/Modify Tools', 'Test Case': 'All io_uring variants', 'io_uring Evasion': 'Primary finding'},\n",
    "])\n",
    "print('=== MITRE ATT&CK Mapping ===')\n",
    "print(mitre.to_string(index=False))\n",
    "mitre.to_csv(TABLES_DIR / 'mitre_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 10) Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('EXECUTIVE SUMMARY')\n",
    "print('='*70)\n",
    "print(f'Total runs: {len(df)}')\n",
    "print(f'Iterations: {df.iteration.nunique()}')\n",
    "\n",
    "trad_df = df[df['method'] == 'traditional']\n",
    "uring_df = df[df['method'] == 'io_uring']\n",
    "\n",
    "print(f'\\nTraditional detection rate: {trad_df.audit_detected.mean():.1%}')\n",
    "print(f'io_uring detection rate: {uring_df.audit_detected.mean():.1%}')\n",
    "\n",
    "file_trad = df[(df['method'] == 'traditional') & (df['path_hits'] >= 0)]\n",
    "file_uring = df[(df['method'] == 'io_uring') & (df['path_hits'] >= 0)]\n",
    "if len(file_trad) > 0 and len(file_uring) > 0:\n",
    "    trad_path = (file_trad['path_hits'] > 0).mean()\n",
    "    uring_path = (file_uring['path_hits'] > 0).mean()\n",
    "    print(f'\\nPath-specific detection (Traditional): {trad_path:.1%}')\n",
    "    print(f'Path-specific detection (io_uring): {uring_path:.1%}')\n",
    "    print(f'\\n>>> EVASION EFFECTIVENESS: {(trad_path - uring_path)*100:.1f}%')\n",
    "\n",
    "print(f'\\nio_uring setup detection: {uring_df.iouring_detected.mean():.1%}')\n",
    "print('\\nConclusion: io_uring bypasses syscall monitoring.')\n",
    "print('Defenders can detect setup but not operations.')\n",
    "print('='*70)\n",
    "print(f'\\nFigures: {list(FIGURES_DIR.glob(\"*.png\"))}')\n",
    "print(f'Tables: {list(TABLES_DIR.glob(\"*.csv\"))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
