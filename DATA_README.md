# DATA_README — Data Collection and Processing

## Overview
This project generates **derived, reproducible metrics** from system telemetry collected during controlled experimental runs. Raw logs are collected locally and processed into summarized CSV outputs that are tracked in this repository.

This follows a reproducible workflow:
**collect → process → save → document**

## Data Sources

### Target VM (RHEL)
- **auditd logs**
  - Primary source of syscall telemetry
  - Example path: `/var/log/audit/audit.log`
  - Logs are queried or exported over a defined time window per run

- **Ground-truth artifacts**
  - Files or program output generated by the workload
  - Used to confirm the workload executed successfully

### Wazuh Manager VM
- **Wazuh alerts**
  - Example path: `/var/ossec/logs/alerts/alerts.json`
  - Used to measure detection coverage and alert timing

> Exact paths and configurations are documented in `environment/setup.md`.

## Per-Run Metadata
Each experimental run is identified by a `run_id` (UTC timestamp) and records:

- run_id
- workload type (`baseline` or `io_uring`)
- target OS and kernel version
- Wazuh agent and manager versions
- auditd enabled status
- run duration (seconds)
- collection timestamp (UTC)

This metadata is stored alongside metrics in a JSON file.

## Processing Steps
`scripts/process_logs.py` performs the following:

1. Loads raw auditd and Wazuh alert data for the specified `run_id`
2. Computes derived metrics, including:
   - total audit event count
   - total Wazuh alert count
   - time to first alert (if applicable)
3. Writes reproducible outputs to the `data/processed/` directory

## Output Files

### Metrics CSV
`data/processed/run_<RUN_ID>_metrics.csv`

Minimum columns:
- run_id
- workload
- audit_events
- wazuh_alerts
- time_to_first_alert_sec
- duration_sec

### Metadata JSON
`data/processed/run_<RUN_ID>_metadata.json`

Contains:
- run_id
- workload
- target OS and kernel
- Wazuh versions
- duration
- collection timestamp

## Notes on Reproducibility
Exact metric values may vary slightly due to kernel scheduling and log buffering. Reproducibility is defined by:
- consistent experimental workflow
- identical output schemas
- comparable detection trends under equivalent configurations

